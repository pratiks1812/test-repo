{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd \n",
    "import pyodbc\n",
    "import nest_asyncio\n",
    "import os \n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "\n",
    "nest_asyncio.apply()\n",
    "pd.options.mode.chained_assignment = None # suppressed warning if writing to df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "current_year = today.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar, datetime as dt\n",
    "\n",
    "def get_date(day, month, year):\n",
    "    \"\"\"\n",
    "    Takes three integer values: day, month and year, and converts them to a datetime object\n",
    "    \"\"\"\n",
    "    # handle two digit years \n",
    "    if year < 100:\n",
    "        year += 1900 if year >= 50 else 2000\n",
    "        \n",
    "    calendar_days = calendar.monthrange(year, month)[1]\n",
    "    # check if day is less than 1 and adjust to previous month\n",
    "    if day < 1:\n",
    "        # shift back month by 1\n",
    "        \n",
    "        month -= 1 \n",
    "        if month < 1:\n",
    "            # adjust the month \n",
    "            month = 12 \n",
    "            year -= 1\n",
    "        \n",
    "        calendar_days = calendar.monthrange(year, month)[1]\n",
    "        day = calendar_days\n",
    "\n",
    "    if day > calendar_days:\n",
    "        date_obj = datetime(year, month, 1) + dt.timedelta(day - 1)\n",
    "    else:\n",
    "        date_obj = datetime(year, month, day)\n",
    "\n",
    "      \n",
    "    return date_obj.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of frequently used columns\n",
    "cols = ['AGE',\n",
    " 'BLDSTOOL',\n",
    " 'CHECKUP',\n",
    " 'COLNCNCR',\n",
    " 'COLNSCPY',\n",
    " 'COLNTEST',\n",
    " 'FINALWT',\n",
    " 'HADMAM',\n",
    " 'HADSGCOL',\n",
    " 'HADSIGM',\n",
    " 'HIVRISK',\n",
    " 'HIVTEST',\n",
    " 'HLTHPLAN',\n",
    " 'HOWLONG',\n",
    " 'IDAY',\n",
    " 'IMONTH',\n",
    " 'INCOME2',\n",
    " 'IYEAR',\n",
    " 'LASTSIGM',\n",
    " 'LSTBLDST',\n",
    " 'PERSDOC',\n",
    " 'SDNATEST',\n",
    " 'SEX',\n",
    " 'SIGMSCPY',\n",
    " 'STOOLDNA',\n",
    " 'VCLTEST',\n",
    " 'VIRCOLON',\n",
    " '_AGEG5YR']\n",
    "\n",
    "# column maps \n",
    "colmap = {\n",
    "    'age': 'AGE',\n",
    " '_ageg5yr': '_AGEG5YR',\n",
    " 'persdoc': 'PERSDOC',\n",
    " 'checkup': 'CHECKUP',\n",
    " 'sex': 'SEX',\n",
    "  'hlthplan': 'HLTHPLAN',\n",
    " 'hivtest': 'HIVTEST',\n",
    " 'hivrisk': 'HIVRISK',\n",
    " 'wcol': 'FINALWT',\n",
    " 'income2': 'INCOME2',\n",
    " 'howlong': 'HOWLONG',\n",
    " 'hadmam': 'HADMAM',\n",
    " 'hadsigm': 'HADSIGM',\n",
    " 'hadsgcol': 'HADSGCOL',\n",
    " 'bldstool': 'BLDSTOOL',\n",
    " 'lastsigm': 'LASTSIGM',\n",
    " 'lstbldst': 'LSTBLDST',\n",
    " 'colntest': 'COLNTEST',\n",
    " 'stooldna': 'STOOLDNA',\n",
    " 'vclntest': 'VCLNTEST',\n",
    " 'sdnatest': 'SDNATEST',\n",
    " 'vircolon': 'VIRCOLON',\n",
    " 'colnscpy': 'COLNSCPY',\n",
    " 'sigmscpy': 'SIGMSCPY',\n",
    " 'colncncr': 'COLNCNCR',\n",
    " 'iyear': 'IYEAR',\n",
    " 'imonth': 'IMONTH',\n",
    " 'iday': 'IDAY'\n",
    "}\n",
    "\n",
    "# update to start year at the most recent year of update to prevent attempting to build this dataset from scratch\n",
    "start_year = 2021\n",
    "year = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the BRFSS data breakdown file which contains the updated column names\n",
    "df = pd.read_excel(r\"C:\\Users\\AnkitB\\OneDrive - crisil.com\\backup\\Bernstein\\Input folder - zip\\BRFSS_data_breakdown.xlsx\", \"vars\", index_col='year')\n",
    "# dictionary to host DataFrames \n",
    "frames = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if dataset already exists \n",
    "# accumulated_path = r'S:\\LON_SSRES\\DataAnalytics\\US Life Science\\Data\\Input\\BRFSS_COLORECTAL.csv'\n",
    "# accumulated_path = r'R:\\Life science tools and diagnostics\\Topical analyses\\EXAS deep dive\\BRFSS\\Jasmeen\\Old\\Input\\2023\\BRFSS Filtered Dataset - Copy.csv'\n",
    "# accumulated_path = r'C:\\Users\\AnkitB\\OneDrive - crisil.com\\backup\\Bernstein\\output_test\\BRFSS_COLORECTAL_2021.csv'\n",
    "accumulated_path = r'C:\\Users\\AnkitB\\OneDrive - crisil.com\\backup\\Bernstein\\output_test\\updated_data_column_names.csv'\n",
    "\n",
    "if os.path.exists(accumulated_path):\n",
    "    # if dataset exists, then we want to import the data so that it can be updated\n",
    "    df2 = pd.read_csv(accumulated_path, parse_dates=['IDATE'])\n",
    "    df2.rename(columns = {'VCLTEST': 'VCLNTEST'}, inplace=True)\n",
    "else:\n",
    "    # if the dataset doesn't exist, create an empty dataframe. Reduces chance of error\n",
    "    df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate df2 then append the new dat to the frame\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding 2021 to frames dictionary ...: : 1it [02:37, 157.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create progress bar to track progres of the data reading\n",
    "bar = tqdm(df.loc[start_year:start_year, :].iterrows(), desc=('Reading %s row:' % year))\n",
    "# bar = tqdm(df.iterrows(), desc=('Reading %s row:' % year))\n",
    "\n",
    "for year, row in bar:\n",
    "    # identify file location and create output path name in case of code break \n",
    "    folder, filename = os.path.split(row.fileloc)\n",
    "    output_filename = os.path.splitext(filename)[0] +'.csv'\n",
    "\n",
    "    bar.set_description('Reading %s data' % year)\n",
    "    df1 = pd.read_sas(row.fileloc)\n",
    "    row = row.dropna()\n",
    "    indx = [x for x in row.index if not x in ['fileloc']]\n",
    " \n",
    "    \n",
    "    bar.set_description(f'Updating {year} column names...')\n",
    "    df1 = df1.rename(columns={v.upper():colmap[k] for k,v in row.loc[indx].items()})\n",
    "    df1['IDATE'] = df1.apply(lambda row: get_date(day=int(row.IDAY), month=int(row.IMONTH), year=int(row.IYEAR)),axis=1)\n",
    "    df1['DATAYEAR'] = year\n",
    "\n",
    "    bar.set_description(f'Appending {year} to full dataset ...')\n",
    "    data = pd.concat([data, df1], ignore_index=True)\n",
    "\n",
    "    bar.set_description(f'Saving {year} as {filename}.csv ...')\n",
    "    df1.to_csv(os.path.join(folder, output_filename), index=False)\n",
    "\n",
    "\n",
    "    bar.set_description(f'Adding {year} to frames dictionary ...')\n",
    "    frames[year] = df1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year, row in df.loc[1998:2010].iterrows():\n",
    "#     folder, filename = os.path.split(row.fileloc)\n",
    "#     output_filename = os.path.splitext(filename)[0] +'.csv'\n",
    "#     df1 = pd.read_csv(os.path.join(folder,output_filename))\n",
    "#     types = df1.dtypes\n",
    "#     notfloats = types[~types.eq(float)]\n",
    "#     for col in notfloats.keys():\n",
    "#         try:\n",
    "#             df1[col] = df1[col].apply(lambda x: eval(x).decode('utf-8'))\n",
    "#         except:\n",
    "#             continue\n",
    "#         if col == 'INTVID':\n",
    "#             continue\n",
    "#         elif col == 'IDATE':\n",
    "#             df1[col] = df1[col].apply(get_date)\n",
    "#         else:\n",
    "#             try:\n",
    "#                 df1[col] = df1[col].apply(lambda x: float(x) if len(x) > 0 else None)\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "#     # update float types again:\n",
    "#     types = df1.dtypes\n",
    "#     floats_only = types[types.eq(float)]\n",
    "#     for col in floats_only.keys():\n",
    "#         df1[col] = df1[col].apply(lambda x: x if not x.is_integer() else int(x))\n",
    "        \n",
    "#     # rename columns\n",
    "#     row = row.dropna()\n",
    "#     indx = [x for x in row.index if not x in ['fileloc']]\n",
    "    \n",
    "#     df1 = df1.rename(columns={v:colmap[k] for k,v in row.loc[indx].items()})\n",
    "#     print('Updating', output_filename, '...')\n",
    "#     df1.to_csv(os.path.join(folder,output_filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm \n",
    "# bar = tqdm(df.loc[start_year:].iterrows())\n",
    "# # bar = tqdm(frames.items())\n",
    "# # this will hold the data from the newly added data\n",
    "# data = pd.DataFrame()\n",
    "\n",
    "# for year, row in bar:\n",
    "#     # get the file location\n",
    "#     folder, filename = os.path.split(row.fileloc)\n",
    "#     # define output file hname\n",
    "#     output_filename = os.path.splitext(filename)[0] +'.csv'\n",
    "    \n",
    "\n",
    "#     bar.set_description(f'Reading {output_filename}...')\n",
    "    \n",
    "#     if not year in frames:\n",
    "#         # read the CSV file that was created earlier to \n",
    "#         df1 = pd.read_csv(os.path.join(folder,output_filename), usecols=lambda x: x in cols,dtype={'IMONTH': bytes, 'IDAY': bytes, 'IYEAR':bytes})\n",
    "#         # the day, month and year variables might be stored as bytes. This will transform them into ints \n",
    "#         df1['IDAY'] = df1['IDAY'].apply(eval).astype(int)\n",
    "#         df1['IMONTH'] = df1['IMONTH'].apply(eval).astype(int)\n",
    "#         df1['IYEAR'] = df1['IYEAR'].apply(eval).astype(int)\n",
    "\n",
    "#     else:\n",
    "#         df1 = frames[year]\n",
    "\n",
    "#     df1['IDATE'] = df1.apply(lambda row: get_date(day=int(row.IDAY), month=int(row.IMONTH), year=int(row.IYEAR)),axis=1)\n",
    "#     df1['DATAYEAR'] = year\n",
    "#     data = pd.concat([data, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.concat([df2, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(r'C:\\Users\\AnkitB\\OneDrive - crisil.com\\backup\\Bernstein\\output_test\\new\\BRFSS_COLORECTAL.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'int64': 'numeric(18,0)', 'float64': 'decimal(28,0)', 'object': 'varchar(50)', 'datetime64[ns]': 'datetime' }\n",
    "dtypes = data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(',\\n'.join(f'[{k}] {types[v.name]}' for k, v in dtypes.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
